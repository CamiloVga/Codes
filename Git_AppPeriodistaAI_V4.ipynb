{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamiloVga/Codes/blob/main/Git_AppPeriodistaAI_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# App todo en uno de producción de noticias"
      ],
      "metadata": {
        "id": "OcGkkrB8yVIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código paso a paso para crear una app de gradio para escribir noticia por medio de GPT-3.5-turbo y Whisper de OpenAi\n",
        "\n",
        "La herramienta recibe y transcribe audios de reportería, entiende los hechos y las instrucciones para escribir un contenido funcional.\n",
        "\n",
        "Creado por: [Camilo Vega ](https://www.linkedin.com/in/camilo-vega-169084b1/)"
      ],
      "metadata": {
        "id": "x4-noXs3yr10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install transformers\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install pydub\n",
        "!pip install PyMuPDF\n",
        "!pip install python-docx\n",
        "!pip install pandas\n",
        "!pip install gradio\n",
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "qyypEAXomLpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar las librerias\n",
        "\n",
        "import openai\n",
        "\n",
        "import whisper\n",
        "\n",
        "import tempfile\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "from pydub import AudioSegment\n",
        "\n",
        "import fitz  # PyMuPDF para manejar PDFs\n",
        "\n",
        "import docx  # Para manejar archivos .docx\n",
        "\n",
        "import pandas as pd  # Para manejar archivos .xlsx y .csv\n",
        "\n",
        "\n",
        "\n",
        "# Configura tu clave API de OpenAI\n",
        "\n",
        "openai.api_key = \"API KEY\"\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el modelo Whisper de mayor calidad\n",
        "\n",
        "model = whisper.load_model(\"medium\")\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_audio(audio_file):\n",
        "\n",
        "    \"\"\"Preprocesa el archivo de audio para mejorar la calidad.\"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "        # Normaliza el audio al -20 dBFS\n",
        "\n",
        "        audio = audio.apply_gain(-audio.dBFS + (-20))\n",
        "\n",
        "        # Exporta el audio procesado a un archivo temporal\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
        "\n",
        "            audio.export(temp_file.name, format=\"mp3\")\n",
        "\n",
        "            return temp_file.name\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return f\"Error al preprocesar el archivo de audio: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "def transcribir_audio(audio_file):\n",
        "\n",
        "    \"\"\"Transcribe un archivo de audio.\"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        if isinstance(audio_file, str):\n",
        "\n",
        "            archivo_path = preprocess_audio(audio_file)\n",
        "\n",
        "        else:\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
        "\n",
        "                temp_file.write(audio_file.read())\n",
        "\n",
        "                temp_file.flush()\n",
        "\n",
        "                archivo_path = preprocess_audio(temp_file.name)\n",
        "\n",
        "        resultado = model.transcribe(archivo_path)\n",
        "\n",
        "        return resultado.get(\"text\", \"Error en la transcripción\")\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return f\"Error al procesar el archivo de audio: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "def leer_documento(documento_path):\n",
        "\n",
        "    \"\"\"Lee el contenido de un documento PDF, DOCX, XLSX o CSV.\"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Identificar el tipo de archivo\n",
        "\n",
        "        if documento_path.endswith(\".pdf\"):\n",
        "\n",
        "            doc = fitz.open(documento_path)\n",
        "\n",
        "            texto_completo = \"\"\n",
        "\n",
        "            for pagina in doc:\n",
        "\n",
        "                texto_completo += pagina.get_text()\n",
        "\n",
        "            return texto_completo\n",
        "\n",
        "        elif documento_path.endswith(\".docx\"):\n",
        "\n",
        "            doc = docx.Document(documento_path)\n",
        "\n",
        "            texto_completo = \"\\n\".join([parrafo.text for parrafo in doc.paragraphs])\n",
        "\n",
        "            return texto_completo\n",
        "\n",
        "        elif documento_path.endswith(\".xlsx\"):\n",
        "\n",
        "            df = pd.read_excel(documento_path)\n",
        "\n",
        "            texto_completo = df.to_string()\n",
        "\n",
        "            return texto_completo\n",
        "\n",
        "        elif documento_path.endswith(\".csv\"):\n",
        "\n",
        "            df = pd.read_csv(documento_path)\n",
        "\n",
        "            texto_completo = df.to_string()\n",
        "\n",
        "            return texto_completo\n",
        "\n",
        "        else:\n",
        "\n",
        "            return \"Tipo de archivo no soportado. Por favor suba un documento PDF, DOCX, XLSX o CSV.\"\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return f\"Error al leer el documento: {str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "def generar_noticia(instrucciones, hechos, tamaño, tono, *args):\n",
        "\n",
        "    \"\"\"Genera una noticia a partir de instrucciones, hechos y transcripciones.\"\"\"\n",
        "\n",
        "    base_de_conocimiento = {\n",
        "\n",
        "        \"instrucciones\": instrucciones,\n",
        "\n",
        "        \"hechos\": hechos,\n",
        "\n",
        "        \"contenido_documentos\": [],\n",
        "\n",
        "        \"audio_data\": []\n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    # Recolecta los documentos y el audio desde los argumentos\n",
        "\n",
        "    num_audios = 5 * 3  # 5 audios * 3 campos (audio, nombre, cargo)\n",
        "\n",
        "    audios = args[:num_audios]\n",
        "\n",
        "    documentos = args[num_audios:]\n",
        "\n",
        "\n",
        "\n",
        "    # Leer el contenido de los documentos si se han subido\n",
        "\n",
        "    for documento in documentos:\n",
        "\n",
        "        if documento is not None:\n",
        "\n",
        "            contenido_doc = leer_documento(documento.name)\n",
        "\n",
        "            print(f\"Contenido del documento {documento.name}: {contenido_doc}\")\n",
        "\n",
        "            base_de_conocimiento[\"contenido_documentos\"].append(contenido_doc)\n",
        "\n",
        "\n",
        "\n",
        "    # Recolecta datos de cada archivo de audio\n",
        "\n",
        "    for i in range(0, len(audios), 3):\n",
        "\n",
        "        audio_file, nombre, cargo = audios[i:i+3]\n",
        "\n",
        "        if audio_file is not None:\n",
        "\n",
        "            base_de_conocimiento[\"audio_data\"].append({\"audio\": audio_file, \"nombre\": nombre, \"cargo\": cargo})\n",
        "\n",
        "\n",
        "\n",
        "    transcripciones_texto = \"\"\n",
        "\n",
        "    transcripciones_brutas = \"\"\n",
        "\n",
        "    total_citas_directas = 0\n",
        "\n",
        "\n",
        "\n",
        "    # Transcribe y compila las transcripciones\n",
        "\n",
        "    for idx, data in enumerate(base_de_conocimiento[\"audio_data\"]):\n",
        "\n",
        "        if data[\"audio\"] is not None:\n",
        "\n",
        "            transcripcion = transcribir_audio(data[\"audio\"])\n",
        "\n",
        "            transcripcion_texto = f'\"{transcripcion}\" - {data[\"nombre\"]}, {data[\"cargo\"]}'\n",
        "\n",
        "            transcripcion_bruta = f'[Audio {idx + 1}]: \"{transcripcion}\" - {data[\"nombre\"]}, {data[\"cargo\"]}'\n",
        "\n",
        "\n",
        "\n",
        "            # Decidir si usar cita directa o indirecta\n",
        "\n",
        "            if total_citas_directas < len(base_de_conocimiento[\"audio_data\"]) * 0.8:\n",
        "\n",
        "                transcripciones_texto += transcripcion_texto + \"\\n\"\n",
        "\n",
        "                total_citas_directas += 1\n",
        "\n",
        "            else:\n",
        "\n",
        "                transcripciones_texto += f'{data[\"nombre\"]} mencionó que {transcripcion}' + \"\\n\"\n",
        "\n",
        "\n",
        "\n",
        "            transcripciones_brutas += transcripcion_bruta + \"\\n\\n\"\n",
        "\n",
        "\n",
        "\n",
        "            print(f\"Transcripción bruta [Audio {idx + 1}]: {transcripcion_bruta}\")\n",
        "\n",
        "            print(f\"Transcripciones brutas acumuladas: {transcripciones_brutas}\")\n",
        "\n",
        "\n",
        "\n",
        "    contenido_documentos = \"\\n\\n\".join(base_de_conocimiento[\"contenido_documentos\"])\n",
        "\n",
        "\n",
        "\n",
        "    # Prompt adicional para instrucciones internas\n",
        "\n",
        "    prompt_interno = \"\"\"\n",
        "\n",
        "    Instrucciones para el modelo:\n",
        "\n",
        "    - Asegúrate de que al menos el 80% de las citas sean directas y estén entrecomilladas.\n",
        "\n",
        "    - El 20% restante puede ser citas indirectas.\n",
        "\n",
        "    - No inventes información nueva.\n",
        "\n",
        "    - Sé riguroso con los hechos proporcionados.\n",
        "\n",
        "    - Al procesar los documentos cargados, extrae y resalta citas importantes y testimonios textuales de las fuentes.\n",
        "\n",
        "    - Al procesar los documentos cargados, extrae y resalta cifras clave.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Compila el prompt para OpenAI\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    {prompt_interno}\n",
        "\n",
        "    Escribe una noticia con la siguiente información, incluyendo un título, un sumario de 20 palabras, y el cuerpo del contenido cuyo tamaño es {tamaño} palabras. El tono debe ser {tono}.\n",
        "\n",
        "    Instrucciones: {base_de_conocimiento[\"instrucciones\"]}\n",
        "\n",
        "    Hechos: {base_de_conocimiento[\"hechos\"]}\n",
        "\n",
        "    Contenido adicional de los documentos: {contenido_documentos}\n",
        "\n",
        "    Utiliza las siguientes transcripciones como citas directas e indirectas (sin cambiar ni inventar contenido):\n",
        "\n",
        "    {transcripciones_texto}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    try:\n",
        "\n",
        "        respuesta = openai.ChatCompletion.create(\n",
        "\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "\n",
        "            temperature=0.1  # Bajamos la temperatura para mayor rigurosidad\n",
        "\n",
        "        )\n",
        "\n",
        "        noticia = respuesta['choices'][0]['message']['content']\n",
        "\n",
        "        return noticia, transcripciones_brutas\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        return f\"Error al generar la noticia: {str(e)}\", \"\"\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(\"## Chatbot de noticias\")\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "\n",
        "            instrucciones = gr.Textbox(label=\"Instrucciones para la noticia\", lines=2)\n",
        "\n",
        "            hechos = gr.Textbox(label=\"Describe los hechos de la noticia\", lines=4)\n",
        "\n",
        "            tamaño = gr.Number(label=\"Tamaño del cuerpo de la noticia (en palabras)\", value=100)\n",
        "\n",
        "            tono = gr.Dropdown(label=\"Tono de la noticia\", choices=[\"serio\", \"neutral\", \"divertido\"], value=\"neutral\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "\n",
        "            inputs_list = [instrucciones, hechos, tamaño, tono]\n",
        "\n",
        "            with gr.Tabs():\n",
        "\n",
        "                for i in range(1, 6):\n",
        "\n",
        "                    with gr.TabItem(f\"Audio {i}\"):\n",
        "\n",
        "                        audio = gr.Audio(type=\"filepath\", label=f\"Audio {i}\")\n",
        "\n",
        "                        nombre = gr.Textbox(label=\"Nombre\", scale=1)\n",
        "\n",
        "                        cargo = gr.Textbox(label=\"Cargo\", scale=1)\n",
        "\n",
        "                        inputs_list.extend([audio, nombre, cargo])\n",
        "\n",
        "                for i in range(1, 6):\n",
        "\n",
        "                    with gr.TabItem(f\"Documento {i}\"):\n",
        "\n",
        "                        documento = gr.File(label=f\"Documento {i}\", type=\"filepath\", file_count=\"single\")\n",
        "\n",
        "                        inputs_list.append(documento)\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        generar = gr.Button(\"Generar noticia\")\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        noticia_output = gr.Textbox(label=\"Noticia generada\", lines=20)\n",
        "\n",
        "    with gr.Row():\n",
        "\n",
        "        transcripciones_output = gr.Textbox(label=\"Transcripciones brutas de los audios\", lines=10)\n",
        "\n",
        "\n",
        "\n",
        "    generar.click(fn=generar_noticia, inputs=inputs_list, outputs=[noticia_output, transcripciones_output])\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "qtFyrKWmjHq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNgn91+nRVrJk6bCJJ5oQhZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}